{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "from torch.nn import DataParallel\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "import tqdm\n",
    "import sys\n",
    "import pyfaidx\n",
    "sys.path.append(\"../src/regulatory_lm/\")\n",
    "from evals.nucleotide_dependency import *\n",
    "from modeling.model import *\n",
    "from utils.viz_sequence import *\n",
    "from utils.bpnet import BPNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs supervised count prediction on two sets of generated sequences using the ChromBPNet models which were used as targets for these celltype-specific generations. It is intended to verify that the generations are indeed cell type-specific. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, we load the genome and define the reference sequence used to make insertions\n",
    "#You'll need to replace the genome with your own path\n",
    "genome = \"/mnt/lab_data2/regulatory_lm/oak_backup/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta\"\n",
    "genome_data = pyfaidx.Fasta(genome, sequence_always_upper=True)\n",
    "chrom = \"chr4\"\n",
    "seq_len = 2114\n",
    "start = 39469376\n",
    "end = 39469725\n",
    "midpoint = (start + end) // 2\n",
    "start = midpoint - seq_len // 2\n",
    "end = midpoint + seq_len // 2\n",
    "print(midpoint, start, end)\n",
    "dna_seq = genome_data[chrom][start:end].seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dna_to_one_hot(seqs):\n",
    "    \"\"\"\n",
    "    Converts a list of DNA (\"ACGT\") sequences to one-hot encodings, where the\n",
    "    position of 1s is ordered alphabetically by \"ACGT\". `seqs` must be a list\n",
    "    of N strings, where every string is the same length L. Returns an N x L x 4\n",
    "    Pytorch tensor of one-hot encodings, in the same order as the input sequences.\n",
    "    All bases will be converted to upper-case prior to performing the encoding.\n",
    "    Any bases that are not \"ACGT\" will be given an encoding of all 0s.\n",
    "    \"\"\"\n",
    "    seq_len = len(seqs[0])\n",
    "    assert np.all(np.array([len(s) for s in seqs]) == seq_len)\n",
    "\n",
    "    # Join all sequences together into one long string, all uppercase\n",
    "    seq_concat = \"\".join(seqs).upper() + \"ACGT\"\n",
    "    # Add one example of each base, so np.unique doesn't miss indices later\n",
    "\n",
    "    one_hot_map = np.identity(5)[:, :-1].astype(np.int8)\n",
    "\n",
    "    # Convert string into array of ASCII character codes;\n",
    "    base_vals = np.frombuffer(bytearray(seq_concat, \"utf8\"), dtype=np.int8)\n",
    "\n",
    "    # Anything that's not an A, C, G, or T gets assigned a higher code\n",
    "    base_vals[~np.isin(base_vals, np.array([65, 67, 71, 84]))] = 85\n",
    "\n",
    "    # Convert the codes into indices in [0, 4], in ascending order by code\n",
    "    _, base_inds = np.unique(base_vals, return_inverse=True)\n",
    "\n",
    "    # Get the one-hot encoding for those indices, and reshape back to separate\n",
    "    return torch.tensor(one_hot_map[base_inds[:-4]].reshape((len(seqs), seq_len, 4))).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_predict_counts(supervised_model, seq_str, device):\n",
    "    '''\n",
    "    Takes in a DNA sequence as a string and uses a supervised bpnet-style model to predict counts over the region\n",
    "    '''\n",
    "    one_hot_seq = dna_to_one_hot([seq_str]).to(device)\n",
    "    with torch.no_grad():\n",
    "        supervised_pred = supervised_model(one_hot_seq)\n",
    "    return supervised_pred[1].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, we define the two ChromBPNet models we are using (again replace with your own path)\n",
    "#In the paper example, we had one from HEPG2 and one from H1-hESC\n",
    "hepg2_model_file = \"/oak/stanford/groups/akundaje/projects/chromatin-atlas-2022/DNASE/ENCSR149XIL/chrombpnet_model/chrombpnet_wo_bias.h5\"\n",
    "hepg2_chrombpnet_model = BPNet.from_keras(hepg2_model_file)\n",
    "hepg2_chrombpnet_model = hepg2_chrombpnet_model.to(device)\n",
    "\n",
    "h1esc_model_file = \"/oak/stanford/groups/akundaje/projects/chromatin-atlas-2022/DNASE/ENCSR000EMU/chrombpnet_model/chrombpnet_wo_bias.h5\"\n",
    "h1esc_chrombpnet_model = BPNet.from_keras(h1esc_model_file)\n",
    "h1esc_chrombpnet_model = h1esc_chrombpnet_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will now take in our generated sequences (again replace with your path)\n",
    "hepg2_seqs_file = \"/mnt/lab_data2/regulatory_lm/scratch/transformer_test/run_20251231_230449/generated_seqs/hepg2_high_modisco/hepg2_high_vs_h1esc_allruns.txt\"\n",
    "hepg2_seqs = [x.strip() for x in open(hepg2_seqs_file, \"r\")]\n",
    "\n",
    "h1esc_seqs_file = \"/mnt/lab_data2/regulatory_lm/scratch/transformer_test/run_20251231_230449/generated_seqs/h1esc_high_modisco/h1esc_high_vs_hepg2_allruns.txt\"\n",
    "h1esc_seqs = [x.strip() for x in open(h1esc_seqs_file, \"r\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We perform counts prediction using both models on both sets of sequences\n",
    "hepg2_counts_high, hepg2_counts_low = [], []\n",
    "for seq in hepg2_seqs:\n",
    "    center_start, center_end = 882, 1232\n",
    "    dna_seq = dna_seq[:center_start] + seq + dna_seq[center_end:]\n",
    "    with torch.no_grad():\n",
    "        hepg2_counts_high.append(supervised_predict_counts(hepg2_chrombpnet_model, dna_seq, device))\n",
    "\n",
    "for seq in h1esc_seqs:\n",
    "    center_start, center_end = 882, 1232\n",
    "    dna_seq = dna_seq[:center_start] + seq + dna_seq[center_end:]\n",
    "    with torch.no_grad():\n",
    "        hepg2_counts_low.append(supervised_predict_counts(hepg2_chrombpnet_model, dna_seq, device))\n",
    "    \n",
    "    \n",
    "h1esc_counts_high, h1esc_counts_low = [], []\n",
    "for seq in hepg2_seqs:\n",
    "    center_start, center_end = 882, 1232\n",
    "    dna_seq = dna_seq[:center_start] + seq + dna_seq[center_end:]\n",
    "    with torch.no_grad():\n",
    "        h1esc_counts_low.append(supervised_predict_counts(h1esc_chrombpnet_model, dna_seq, device))\n",
    "\n",
    "for seq in h1esc_seqs:\n",
    "    center_start, center_end = 882, 1232\n",
    "    dna_seq = dna_seq[:center_start] + seq + dna_seq[center_end:]\n",
    "    with torch.no_grad():\n",
    "        h1esc_counts_high.append(supervised_predict_counts(h1esc_chrombpnet_model, dna_seq, device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(hepg2_counts_high), np.mean(hepg2_counts_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(h1esc_counts_high), np.mean(h1esc_counts_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#We can plot the stats from both models and verify the sequences are as desired\n",
    "import seaborn as sns\n",
    "plt.figure(dpi=300, figsize=[6,2])\n",
    "sns.kdeplot(hepg2_counts_high, lw=2, label=\"HEPG2 High\")\n",
    "sns.kdeplot(hepg2_counts_low, lw=2, label=\"H1ESC High\")\n",
    "plt.title(\"HEPG2 ChromBPNet Predicted Counts\")\n",
    "plt.xlabel(\"Predicted Counts\")\n",
    "plt.yticks([])\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300, figsize=[6,2])\n",
    "plt.title(\"H1ESC ChromBPNet Predicted Counts\")\n",
    "sns.kdeplot(h1esc_counts_low, lw=2, label=\"HEPG2 High\")\n",
    "sns.kdeplot(h1esc_counts_high, lw=2, label=\"H1ESC High\")\n",
    "plt.xlabel(\"Predicted Counts\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.yticks([])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LanguageModelingEnv",
   "language": "python",
   "name": "languagemodelingenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
