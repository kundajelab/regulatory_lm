{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "from torch.nn import DataParallel\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import json\n",
    "import tqdm\n",
    "import sys\n",
    "import pyfaidx\n",
    "sys.path.append(\"../src/regulatory_lm/\")\n",
    "from evals.nucleotide_dependency import *\n",
    "from modeling.model import *\n",
    "from utils.viz_sequence import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook allows you to analyze a regulatory region using an ARSENAL model. It will perform nucleotide dependency analysis, visualize model predictions with successively masking each token, and visualize model predictions without masking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str_dict = MODULES\n",
    "FLOAT_DTYPES = {\"float32\":torch.float32, \"float64\":torch.float64, \"bfloat16\":torch.bfloat16, \"float16\":torch.float16}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    \n",
    "def encode_sequence(sequence): \n",
    "    encoded_sequence = [MAPPING.get(nucleotide, 4) for nucleotide in sequence]\n",
    "    return encoded_sequence\n",
    "\n",
    "def revcomp(seq_list):\n",
    "    return [3-x for x in seq_list][::-1]\n",
    "\n",
    "def revcomp_string(dna_sequence):\n",
    "    complement = {'A': 'T', 'T': 'A', 'G': 'C', 'C': 'G'}\n",
    "    return ''.join(complement[base] for base in reversed(dna_sequence.upper()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(args_json, saved_model_file):\n",
    "    args = json.load(open(args_json, \"r\"))\n",
    "    embedder_kwargs = args.get(\"embedder_kwargs\", {})\n",
    "    encoder_kwargs = args.get(\"encoder_kwargs\", {})\n",
    "    decoder_kwargs = args.get(\"decoder_kwargs\", {})\n",
    "    model_kwargs = args.get(\"model_kwargs\", {})\n",
    "\n",
    "\n",
    "    embedder = model_str_dict[args[\"embedder\"]](args[\"embedding_size\"], vocab_size=args[\"num_real_tokens\"]+2, masking=True, **embedder_kwargs)\n",
    "    encoder = model_str_dict[args[\"encoder\"]](args[\"embedding_size\"], args[\"num_encoder_layers\"], **encoder_kwargs)\n",
    "    decoder = model_str_dict[args[\"decoder\"]](args[\"embedding_size\"], **decoder_kwargs)\n",
    "    model = RegulatoryLM(embedder, encoder, decoder)\n",
    "    model_info = torch.load(saved_model_file)\n",
    "    if list(model_info[\"model_state\"].keys())[0][:7] == \"module.\":\n",
    "        model_info[\"model_state\"] = {x[7:]:model_info[\"model_state\"][x] for x in model_info[\"model_state\"]}\n",
    "    else:\n",
    "        model = torch.compile(model)\n",
    "    model.load_state_dict(model_info[\"model_state\"])\n",
    "    model.eval()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(scores, demarcs=[], limits=None):\n",
    "    plt.figure(dpi=300, figsize=[16,8])\n",
    "    plot_weights(scores)\n",
    "    plt.xticks([])\n",
    "    max_val = np.abs(scores).max()\n",
    "    if max_val < 0.05:\n",
    "        plt.ylim(-0.05, 0.05)\n",
    "    for motif in demarcs:\n",
    "        plt.axvline(motif[0], color=\"black\")\n",
    "        plt.axvline(motif[1], color=\"black\")\n",
    "    if limits is not None:\n",
    "        plt.ylim(limits[0], limits[1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_and_predict(seq, mask_inds, model, demarcs=[], limits=None):\n",
    "    new_probs = []\n",
    "    one_hot = torch.zeros(1, len(seq), 4, dtype=torch.int8)\n",
    "    seq_encoded_true = encode_sequence(seq)\n",
    "    seq_tensor_true = torch.tensor(seq_encoded_true)\n",
    "    for nuc in range(4):\n",
    "        one_hot[:,:,nuc] = (seq_tensor_true == nuc).to(dtype=torch.int8) # for non ACGT, set to 0\n",
    "    one_hot = one_hot.cpu().numpy(force=True).transpose([0,2,1])\n",
    "    for ind in mask_inds:\n",
    "        seq_encoded = encode_sequence(seq)\n",
    "        seq_encoded[ind] = 5\n",
    "        seq_tensor = torch.tensor(seq_encoded)\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            model = model.to(device)\n",
    "            logits = model(seq_tensor.unsqueeze(0).to(device), None)\n",
    "            probs = F.softmax(logits, dim=-1).to(dtype=torch.float16).permute(0,2,1)\n",
    "            probs_norm = probs.cpu()\n",
    "            new_probs.append(probs_norm[:,:,ind])\n",
    "    for i, ind in enumerate(mask_inds):\n",
    "        probs_norm[:,:,ind] = new_probs[i]\n",
    "    probs_norm = probs_norm.permute(0,2,1)\n",
    "    nuc_average = torch.mean(probs_norm, dim=1)\n",
    "    probs_norm = (probs_norm * torch.log(probs_norm / nuc_average)).permute(0,2,1).numpy()\n",
    "    plot_scores(probs_norm[:,:,min(mask_inds):max(mask_inds) + 1] * one_hot[:,:,min(mask_inds):max(mask_inds) + 1], demarcs, limits)\n",
    "    plot_scores(probs_norm[:,:,min(mask_inds):max(mask_inds) + 1], demarcs, limits)\n",
    "    return probs_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_no_mask(seq, model, demarcs=[], limits=None):\n",
    "    one_hot = torch.zeros(1, len(seq), 4, dtype=torch.int8)\n",
    "    seq_encoded_true = encode_sequence(seq)\n",
    "    seq_tensor = torch.tensor(seq_encoded_true)\n",
    "    for nuc in range(4):\n",
    "        one_hot[:,:,nuc] = (seq_tensor == nuc).to(dtype=torch.int8) # for non ACGT, set to 0\n",
    "    one_hot = one_hot.cpu().numpy(force=True).transpose([0,2,1])\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model = model.to(device)\n",
    "        logits = model(seq_tensor.unsqueeze(0).to(device), torch.tensor([9]).to(device))\n",
    "        probs = F.softmax(logits, dim=-1).to(dtype=torch.float16).permute(0,2,1)\n",
    "        probs_norm = probs.cpu()\n",
    "    probs_norm = probs_norm.permute(0,2,1)\n",
    "    nuc_average = torch.mean(probs_norm, dim=1)\n",
    "    probs_norm = probs_norm.permute(0,2,1).numpy()\n",
    "    entropy_metric = 2 + (probs_norm * np.log2(probs_norm)).sum(1) #We find that entropy-based normalization is slightly better for this one\n",
    "    probs_norm = entropy_metric * probs_norm\n",
    "    plot_scores(probs_norm * one_hot, demarcs, limits)\n",
    "    plot_scores(probs_norm, demarcs, limits)\n",
    "    return probs_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ARSENAL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args_json = \"/mnt/lab_data2/regulatory_lm/scratch/transformer_test/run_20251231_230449/args.json\" #Model args file\n",
    "saved_model_file = \"/mnt/lab_data2/regulatory_lm/scratch/transformer_test/run_20251231_230449/checkpoint_149.pt\" #Model checkpoint file\n",
    "\n",
    "\n",
    "model = load_model(args_json, saved_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define region to study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user must define a reference genome file, chromosome, start, and end. This notebook will then analyze the 350bp sequence centered at the specified location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = \"/oak/stanford/groups/akundaje/patelas/regulatory_lm/data/hg38_repeat_lowercase.fa\"\n",
    "chrom = \"chr11\"\n",
    "seq_len = 350\n",
    "start = 5280547\n",
    "end = 5280890\n",
    "\n",
    "\n",
    "\n",
    "genome_data = pyfaidx.Fasta(genome, sequence_always_upper=True)\n",
    "midpoint = (start + end) // 2\n",
    "start = midpoint - seq_len // 2\n",
    "end = midpoint + seq_len // 2\n",
    "dna_seq = genome_data[chrom][start:end].seq\n",
    "seq_tensor = torch.tensor(encode_sequence(dna_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Nucleotide Dependency Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section runs [nucleotide dependency analysis](https://www.nature.com/articles/s41588-025-02347-3) on the specified sequence. The scores are plotted by default and also returned for further analysis if desired. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = run_dependency_pipeline(model, seq_tensor, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Masked Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section plots masked probabilities across the region, which is very useful for detecting the motifs learned by the model in the sequence. Two plots are produced: one with only the true nucleotides in the sequence, and one with the probabilities for all four nucleotides. There are a couple of parameters which could aid visualization:\n",
    "\n",
    "`limits`: an iterable of two values specifying the minimum and maximum y values. Example: `[0, 1.5]`\n",
    "\n",
    "`demarcs`: an iterable of iterables, with each one containing start and end indices of desired parts of the sequence. Vertical lines will be drawn at each location specified, allowing the user to pinpoint specific regions of the overall sequence. Example: `[(130, 140), (300, 320)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probs_norm = mask_and_predict(dna_seq, list(range(0, 350)), model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Unmasked Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section plots unmasked probabilities across the region. The `limits` and `demarcs` parameters are the same as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_norm = predict_no_mask(dna_seq, model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LanguageModelingEnv",
   "language": "python",
   "name": "languagemodelingenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
