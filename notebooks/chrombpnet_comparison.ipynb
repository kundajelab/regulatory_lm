{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Must have chrombpnet installed - specify the path here\n",
    "chrombpnet_path = \"/users/patelas/lib/chrombpnet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepdish as dd\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import shap\n",
    "from tensorflow import keras\n",
    "import pyfaidx\n",
    "import shutil\n",
    "import pickle as pkl\n",
    "import pyBigWig\n",
    "import errno\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(f\"{chrombpnet_path}/chrombpnet/\")\n",
    "from training.utils.losses import multinomial_nll\n",
    "from training.utils.one_hot import dna_to_one_hot\n",
    "from evaluation.interpret.shap_utils import *\n",
    "sys.path.append(\"../src/regulatory_lm/\")\n",
    "from utils.viz_sequence import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to interpret ARSENAL-generated sequences using [ChromBPNet](https://github.com/kundajelab/chrombpnet/tree/master). It is necessary to use the environment specified by ChromBPNet for this notebook rather than the one provided by ARSENAL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, we define the ChromBPNet h5 model file and reference genome, along with the sequence that formed the base of our generations\n",
    "#Change the paths according to your system\n",
    "model_file = \"/oak/stanford/groups/akundaje/projects/chromatin-atlas-2022/DNASE/ENCSR149XIL/chrombpnet_model/chrombpnet_wo_bias.h5\"\n",
    "genome = \"/mnt/lab_data2/regulatory_lm/oak_backup/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta\"\n",
    "genome_data = pyfaidx.Fasta(genome, sequence_always_upper=True)\n",
    "chrom = \"chr4\"\n",
    "seq_len = 2114\n",
    "start = 39469376\n",
    "end = 39469725\n",
    "midpoint = (start + end) // 2\n",
    "start = midpoint - seq_len // 2\n",
    "end = midpoint + seq_len // 2\n",
    "dna_seq = genome_data[chrom][start:end].seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_middle_seq is the ARSENAL-generated sequence we want to insert in the middle\n",
    "#882 and 1232 are the start and end if the insertion is 350bp, have to edit if not\n",
    "new_middle_seq = \"CAGGGCACCAGAGTGAGTCCCTGCCAAATCAGATCACGCGGTTTTAGGCTGGAATTCTGCTACCCAGGCCAAGAGACTATCAAAACCTCACAGCATTCCTCAGGCACTTCAGGGTGGGACCACCAGGTGGTGCTATCATTGCACCATTCACCTAAAACTTTGGCTGTGTTCCAGGAAGCGACCGAGAAGTTGCTGCTCTGCTGAAATGTATTTGCATGTACAGTTTATTGTCAGCAGAGGTCACTGTTGTACTAGTATAAATTCCCGAGGGAAAAAATTGCAAGACTATTCACTTCTTTCTTCTTTCTTTTTTTTTTTTGGCCCCTCTTTTCTTTTTATTTTTTTAATCT\"\n",
    "center_start, center_end = 882, 1232\n",
    "\n",
    "dna_seq = dna_seq[:center_start] + new_middle_seq + dna_seq[center_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_shap_dict(seqs, scores):\n",
    "    print(seqs.shape, scores.shape)\n",
    "    assert(seqs.shape==scores.shape)\n",
    "    assert(seqs.shape[2]==4)\n",
    "\n",
    "    # construct a dictionary for the raw shap scores and the\n",
    "    # the projected shap scores\n",
    "    # MODISCO workflow expects one hot sequences with shape (None,4,inputlen)\n",
    "    d = {\n",
    "            'raw': {'seq': np.transpose(seqs, (0, 2, 1))},\n",
    "            'shap': {'seq': np.transpose(scores, (0, 2, 1))},\n",
    "            'projected_shap': {'seq': np.transpose(seqs*scores, (0, 2, 1))}\n",
    "        }\n",
    "\n",
    "    return d\n",
    "\n",
    "def softmax(x, temp=1):\n",
    "    norm_x = x - np.mean(x,axis=1, keepdims=True)\n",
    "    return np.exp(temp*norm_x)/np.sum(np.exp(temp*norm_x), axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_out(preds):\n",
    "    logits, counts = preds\n",
    "    probs = softmax(logits)\n",
    "    vals = np.exp(counts[0]) * probs\n",
    "    plt.plot(vals[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, we use the model to predict on the sequence\n",
    "with keras.utils.CustomObjectScope({'multinomial_nll':multinomial_nll, 'tf':tf}):\n",
    "    model = keras.models.load_model(model_file)\n",
    "\n",
    "#Get model predictions\n",
    "one_hot_seqs = dna_to_one_hot([dna_seq])\n",
    "\n",
    "outlen = model.output_shape[0][1]\n",
    "\n",
    "profile_model_input = model.input\n",
    "profile_input = one_hot_seqs\n",
    "counts_model_input = model.input\n",
    "counts_input = one_hot_seqs\n",
    "\n",
    "model_out = model.predict(one_hot_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We plot the predicted values\n",
    "plt.figure(dpi=300, figsize=(16,4))\n",
    "plot_pred_out(model_out)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the predicted counts so we can verify they match what we want\n",
    "logits, counts = model_out\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate importance scores for our sequence using the model\n",
    "profile_model_counts_explainer = shap.explainers.deep.TFDeepExplainer(\n",
    "    (counts_model_input, tf.reduce_sum(model.outputs[1], axis=-1)),\n",
    "    shuffle_several_times,\n",
    "    combine_mult_and_diffref=combine_mult_and_diffref)\n",
    "counts_shap_scores = profile_model_counts_explainer.shap_values(\n",
    "    counts_input, progress_message=100)\n",
    "counts_scores_dict = generate_shap_dict(one_hot_seqs, counts_shap_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot importance scores\n",
    "plt.figure(dpi=300)\n",
    "max_score = counts_scores_dict[\"projected_shap\"][\"seq\"].max()\n",
    "min_score = counts_scores_dict[\"projected_shap\"][\"seq\"].min()\n",
    "plot_weights(counts_scores_dict[\"projected_shap\"][\"seq\"][0][:,seq_len // 2 - 175 : seq_len // 2 + 175], subticks_frequency=100)\n",
    "plt.title(\"ChromBPNet Importance Scores\", fontsize=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chrombpnet-env",
   "language": "python",
   "name": "chrombpnet-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
